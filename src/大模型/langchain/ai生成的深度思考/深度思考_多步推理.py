from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

llm = ChatOpenAI(
    base_url="http://10.5.14.242:8001/v1",
    api_key="dummy-key",
    model_name="DeepSeek-V3-Fast"
)

# æ­¥éª¤1ï¼šé—®é¢˜æ‹†è§£
decompose_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªé—®é¢˜æ‹†è§£ä¸“å®¶ã€‚å°†å¤æ‚é—®é¢˜æ‹†è§£æˆ3-5ä¸ªå­é—®é¢˜ï¼Œæ¯ä¸ªå­é—®é¢˜åº”è¯¥æ˜¯ç‹¬ç«‹å¯è§£å†³çš„ã€‚"),
    ("user", "è¯·å°†ä»¥ä¸‹é—®é¢˜æ‹†è§£æˆå­é—®é¢˜ï¼š{question}")
])

# æ­¥éª¤2ï¼šå­é—®é¢˜è§£ç­”
solve_subproblem_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šåˆ†æå¸ˆã€‚è¯·è¯¦ç»†è§£ç­”ä»¥ä¸‹å­é—®é¢˜ï¼Œæä¾›å…·ä½“çš„åˆ†æå’Œæ¨ç†è¿‡ç¨‹ã€‚"),
    ("user", "å­é—®é¢˜ï¼š{subproblem}\n\nåŸå§‹é—®é¢˜èƒŒæ™¯ï¼š{original_question}")
])

# æ­¥éª¤3ï¼šæ•´åˆç»“è®º
integrate_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæ•´åˆä¸“å®¶ã€‚åŸºäºæ‰€æœ‰å­é—®é¢˜çš„è§£ç­”ï¼Œæ•´åˆå‡ºæœ€ç»ˆçš„å®Œæ•´ç­”æ¡ˆã€‚"),
    ("user", "åŸå§‹é—®é¢˜ï¼š{original_question}\n\nå„å­é—®é¢˜çš„è§£ç­”ï¼š\n{sub_answers}\n\nè¯·æ•´åˆå‡ºå®Œæ•´çš„æœ€ç»ˆç­”æ¡ˆï¼š")
])

output_parser = StrOutputParser()

def multi_step_reasoning(question):
    """å¤šæ­¥æ¨ç†æ·±åº¦æ€è€ƒ"""
    print("=" * 60)
    print("æ·±åº¦æ€è€ƒç»“æœ - å¤šæ­¥æ¨ç†æ³•")
    print("=" * 60)
    
    # æ­¥éª¤1ï¼šæ‹†è§£é—®é¢˜
    print("\nğŸ” æ­¥éª¤1ï¼šé—®é¢˜æ‹†è§£")
    print("-" * 30)
    decompose_chain = decompose_prompt | llm | output_parser
    subproblems = decompose_chain.invoke({"question": question})
    print(subproblems)
    
    # è§£æå­é—®é¢˜ï¼ˆç®€å•æŒ‰è¡Œåˆ†å‰²ï¼Œå®é™…é¡¹ç›®ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æï¼‰
    subproblem_lines = [line.strip() for line in subproblems.split('\n') if line.strip() and ('.' in line or '?' in line)]
    
    # æ­¥éª¤2ï¼šè§£ç­”å­é—®é¢˜
    print("\nğŸ§  æ­¥éª¤2ï¼šå­é—®é¢˜åˆ†æ")
    print("-" * 30)
    solve_chain = solve_subproblem_prompt | llm | output_parser
    sub_answers = []
    
    for i, subproblem in enumerate(subproblem_lines[:5], 1):  # é™åˆ¶æœ€å¤š5ä¸ªå­é—®é¢˜
        print(f"\nå­é—®é¢˜ {i}: {subproblem}")
        answer = solve_chain.invoke({
            "subproblem": subproblem,
            "original_question": question
        })
        sub_answers.append(f"å­é—®é¢˜ {i}: {subproblem}\nè§£ç­”: {answer}")
        print(f"è§£ç­”: {answer[:200]}..." if len(answer) > 200 else f"è§£ç­”: {answer}")
    
    # æ­¥éª¤3ï¼šæ•´åˆç­”æ¡ˆ
    print("\nğŸ¯ æ­¥éª¤3ï¼šæ•´åˆæœ€ç»ˆç­”æ¡ˆ")
    print("-" * 30)
    integrate_chain = integrate_prompt | llm | output_parser
    final_answer = integrate_chain.invoke({
        "original_question": question,
        "sub_answers": "\n\n".join(sub_answers)
    })
    print(final_answer)
    
    return {
        "subproblems": subproblem_lines,
        "sub_answers": sub_answers,
        "final_answer": final_answer
    }

# æ”¹è¿›çš„å¤šæ­¥æ¨ç†ï¼ˆå¸¦éªŒè¯ï¼‰
def enhanced_multi_step_reasoning(question):
    """å¢å¼ºç‰ˆå¤šæ­¥æ¨ç†ï¼ŒåŒ…å«è‡ªæˆ‘éªŒè¯"""
    print("=" * 60)
    print("æ·±åº¦æ€è€ƒç»“æœ - å¢å¼ºç‰ˆå¤šæ­¥æ¨ç†æ³•")
    print("=" * 60)
    
    # æ‰§è¡ŒåŸºç¡€å¤šæ­¥æ¨ç†
    result = multi_step_reasoning(question)
    
    # æ­¥éª¤4ï¼šè‡ªæˆ‘éªŒè¯
    print("\nâœ… æ­¥éª¤4ï¼šç­”æ¡ˆéªŒè¯")
    print("-" * 30)
    
    verify_prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªç­”æ¡ˆéªŒè¯ä¸“å®¶ã€‚è¯·æ£€æŸ¥ä»¥ä¸‹ç­”æ¡ˆæ˜¯å¦é€»è¾‘ä¸€è‡´ã€å®Œæ•´å‡†ç¡®ï¼Œå¹¶æå‡ºå¯èƒ½çš„æ”¹è¿›å»ºè®®ã€‚"),
        ("user", "é—®é¢˜ï¼š{question}\n\nç­”æ¡ˆï¼š{answer}\n\nè¯·éªŒè¯å¹¶è¯„ä¼°è¿™ä¸ªç­”æ¡ˆï¼š")
    ])
    
    verify_chain = verify_prompt | llm | output_parser
    verification = verify_chain.invoke({
        "question": question,
        "answer": result["final_answer"]
    })
    print(verification)
    
    result["verification"] = verification
    return result

if __name__ == '__main__':
    # æµ‹è¯•å¤šæ­¥æ¨ç†
    question = "å¦‚ä½•è®¾è®¡ä¸€ä¸ªå¯æŒç»­å‘å±•çš„æ™ºæ…§åŸå¸‚ç³»ç»Ÿï¼Ÿ"
    enhanced_multi_step_reasoning(question)