from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

# é“¾å¼æ€è€ƒæç¤ºè¯æ¨¡æ¿
cot_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªæ·±åº¦æ€è€ƒä¸“å®¶ã€‚å¯¹äºç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œæ·±åº¦æ€è€ƒï¼š

1. é—®é¢˜åˆ†æï¼šé¦–å…ˆåˆ†æé—®é¢˜çš„å…³é”®è¦ç´ å’ŒèƒŒæ™¯
2. æ€è€ƒè¿‡ç¨‹ï¼šå±•ç¤ºä½ çš„é€æ­¥æ¨ç†è¿‡ç¨‹ï¼ŒåŒ…æ‹¬å¯èƒ½çš„ä¸åŒè§’åº¦
3. å…³é”®å› ç´ ï¼šè¯†åˆ«å½±å“ç­”æ¡ˆçš„å…³é”®å› ç´ 
4. ç»“è®ºæ¨å¯¼ï¼šåŸºäºä»¥ä¸Šåˆ†æå¾—å‡ºæœ€ç»ˆç»“è®º

è¯·ç”¨JSONæ ¼å¼å›å¤ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- analysis: é—®é¢˜åˆ†æ
- thinking_process: æ€è€ƒè¿‡ç¨‹ï¼ˆæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ€è€ƒæ­¥éª¤ï¼‰  
- key_factors: å…³é”®å› ç´ ï¼ˆæ•°ç»„ï¼‰
- conclusion: æœ€ç»ˆç»“è®º"""),
    ("user", "è¯·å¯¹ä»¥ä¸‹é—®é¢˜è¿›è¡Œæ·±åº¦æ€è€ƒï¼š{question}")
])

llm = ChatOpenAI(
    base_url="http://10.5.14.242:8001/v1",
    api_key="dummy-key",
    model_name="DeepSeek-V3-Fast"
)

output_parser = JsonOutputParser()
chain = cot_prompt | llm | output_parser

def deep_think_cot(question):
    """ä½¿ç”¨é“¾å¼æ€è€ƒè¿›è¡Œæ·±åº¦æ€è€ƒ"""
    response = chain.invoke({"question": question})
    
    print("=" * 50)
    print("æ·±åº¦æ€è€ƒç»“æœ - é“¾å¼æ€è€ƒæ³•")
    print("=" * 50)
    
    print("\nğŸ“Š é—®é¢˜åˆ†æ:")
    print(response.get("analysis", ""))
    
    print("\nğŸ§  æ€è€ƒè¿‡ç¨‹:")
    for i, step in enumerate(response.get("thinking_process", []), 1):
        print(f"{i}. {step}")
    
    print("\nğŸ”‘ å…³é”®å› ç´ :")
    for factor in response.get("key_factors", []):
        print(f"â€¢ {factor}")
    
    print("\nğŸ’¡ æœ€ç»ˆç»“è®º:")
    print(response.get("conclusion", ""))
    
    return response

if __name__ == '__main__':
    # æµ‹è¯•æ·±åº¦æ€è€ƒ
    question = "äººå·¥æ™ºèƒ½å¯¹æœªæ¥æ•™è‚²çš„å½±å“"
    deep_think_cot(question)